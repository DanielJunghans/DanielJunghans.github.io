---
layout: post
title: NEAT Project Part 1
date: 2020-6-16 2:13:00-0400
description: 
comments: false
---

<p style="text-align: center;"><font size="+3">Introduction</font></p>
Hello! My name is Daniel Junghans. I am an undergraduate business student that is working in Michigan State University's BEACON Center under the supervision of Dr. Charles Ofria. I began my current research project with a simple question: can I evolve an artificial neural network (ANN) to accurately predict the closing price of a stock? 

<p style="text-align: center;"><font size="+3">NEAT</font></p>
While researching ANNs, I was introduced to the [Neural Evolution of Augmenting Topologies](https://ieeexplore.ieee.org/abstract/document/1004508?casa_token=GvSoqJe__7oAAAAA:4MxGQXXGS6P-w3srDdBVwXhW0vGG8oF9TGfN9W-RmY3o_7dS5259uk6JBSAKauHqO4Fi1gtntw) (NEAT). NEAT was developed by Dr. Kenneth O. Stanely and is a method for evolving ANNs. I am using NEAT for this project because neuroevolution will help my ANNs explore the problem landscape.

<p style="text-align: center;"><font size="+3">Tesla Stock</font></p>
For this project, I am using a stock with a highly volatile price. I want to use a stock with a highly volatile price because I believe it will lead to more versatile and complex algorithms. The company I am using is $TSLA because it meets my volatility requirement with a 52 week price range of $211.00 - $1027.48. 

<p style="text-align: center;"><font size="+3">Stock Data</font></p>
The financial data consists of historical trading data and technical indicators. There are 19 variables in my dataset which serve as inputs for my ANNs. The financial data I decided to use for this research project was largely influenced by [this paper](https://www-mitpressjournals-org.proxy1.cl.msu.edu/doi/full/10.1162/neco_a_01124).


<p style="text-align: center;"><font size="+3">Neat-Python</font></p>

I used the [neat-python](https://neat-python.readthedocs.io/en/latest/) implementation of NEAT for this project. Neat-python is a library with tools that maintain individual genomes (artificial neural networks). These genomes are made up of genes that contain important information about the structure of the algorithm.

<p style="text-align: center;"><font size="+3">Code</font></p>

<h4>Training and Testing Data</h4>
The first thing my program does is split my financial dataset into two pieces. The first 70% of the dataset becomes the training data, and the last 30% of the dataset becomes the testing data. <br />

<h4>Fitness</h4>
The training dataset is first randomly sampled. Then the ANNs produce outputs (closing price predictions) from the sampled data. While the ANNs produce outputs, their error
is determined by subracting the output from the expected output ( closing stock price). 
<br />
<h4>Speciation and Reproduction</h4>
Once the ANNs have completed the training dataset, they are divided up into species based on genomic distance (this is a measure of how similiar genomes are based on their structure). After all ANNs have been put in a species, parents are selected to produce offspring through sexual and asexual reproduction. These offspring will be the next generation of ANNs and have the opportunity to be mutated. This cycle of fitness determination, speciation, selection, reproduction, and mutation will continue for N generations. 
<br />
<h4>Testing Data</h4>
After N generations, my code checks to see if the fitness for the best ANN is lower than a threshold that I set. 

•	If the best ANN's fitness does not meet this threshold, then the ANNs continue to run on the training data for N generations. 

•	When the best ANN does meet this fitness threshold, the best neural network is run on the entire testing dataset. The outputs (stock price predictions) are recorded, and my code checks to see if the most fit neural network is good enough to stop running the program.  


<p style="text-align: center;"><font size="+3">Exploratory Runs</font></p>
After I wrote the intial code, I ran several exploratory runs to make sure everything worked properly. These exploratory runs also helped me understand how NEAT behaves in different conditions. Before using financial data, I used numbers from a sine wave as inputs to see if my ANNs could predict the sine wave. The ANNs were successfull and I made several adjustments to my code. One of these adjustments was lowering the species compatibility threshold because I noticed that most species collapsed after a few hundered generations. 

<p style="text-align: center;"><font size="+3">Current Experiments</font></p>
My first experiment was to see if my ANNs could predict the closing stock price using normalized data. I graphed the best ANNs testing data predicitions for all 50 runs. As a base line, I graphed what it would look like if you used the closing price for the day before as your prediction. 

<div class="img">
    <img class="col three" src="{{ site.baseurl }}/assets/img/graph1.PNG">
</div>

It is instantly clear that the ANNs could not perform as well as the closing price from the day before. I started to investigate what could cause this problem and came up with several hypotheses. My first hypothesis was that only giving the ANNs one activation function hindered their ability to predict large numbers. After giving the ANNs access to all activation functions in the neat-python library, this was the result:

<div class="img">
    <img class="col three" src="{{ site.baseurl }}/assets/img/graph2.PNG">
</div>

The ANNs clearly performed much better with access to all activation functions. Despite this improvement, the ANNs still failed to perform as well as using the closing price from the day before as the prediction. My second hypothesis was that normalizing the data made it dificult for the ANNs to identify important inputs. Here is the result of giving the ANNs access to all activation functions and running them on un-normalized data:

<div class="img">
    <img class="col three" src="{{ site.baseurl }}/assets/img/graph3.PNG">
</div>

My ANNs are now doing as well as the closing price from the day before. The horizontal line added to the residual plot represents the day befores average error.

<p style="text-align: center;"><font size="+3">Future Work</font></p>
This project has come quite far and I have plenty of ideas for the direction of this research project. For future experiments, I plan on experimenting with other selection schemes. I would also like to switch from feed forward to recurrant neural netowrks. 

